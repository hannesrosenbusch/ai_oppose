{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "print(\"entries seem to be lost in both the primary and secondary lit search\")\n",
    "print(\"example of combining dataframes\")\n",
    "print(\"cool output file with YOU WROTE: {extracted_text} AI answered {AI_response}\")\n",
    "print(\"pdf instead of txt for opposition\")\n",
    "print(\"extract_from_paragraphs should have summary function so that summary is shown in output\")\n",
    "\n",
    "article_file = \"data/metaanalysis.pdf\"\n",
    "literature_file = \"full_lit_abstract_search.csv\"\n",
    "\n",
    "###LITERATURE\n",
    "# full_lit_df = generate_literature_csv_from_pdf(article_file, \"Author\", \"Title\", \"Publication Year\", output_path=\"full_lit.csv\")\n",
    "# df = autosearch_missing_abstracts(\"full_lit.csv\", \"full_lit_abstract_search.csv\")\n",
    "# df = manual_entry_abstracts(\"full_lit_abstract_search.csv\", \"full_lit_abstract_search.csv\")\n",
    "# data_formatted = format_texts_from_csv(literature_file, \"Abstract Note\", \"Author\", \"Title\", \"Publication Year\")\n",
    "# data_formatted.to_csv(\"trash.csv\")\n",
    "# vectorstore_folder_name = generate_vectorstore(data_formatted, zotero_file, max_doc_size = 4000)\n",
    "\n",
    "###CLAIMS\n",
    "# claims = extract_focal_claims(article_file, max_claims=3)\n",
    "# sections = extract_claim_per_paragraph(article_file, max_paragraphs=4)\n",
    "\n",
    "###OPPOSITION\n",
    "# relevant_docs = get_relevant_docs(presented_claim, vectorstore_folder_name)\n",
    "# responses, summary_response = generate_adversarial_texts(presented_claim, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The novel claim in this paper is the introduction of the metameta R package and web app, which allows for the calculation and visualization of study-level statistical power in meta-analyses for a range of hypothetical effect sizes.',\n",
       " 'The novel claim in this paper is that the lack of consideration of study-level statistical power in meta-analysis can lead to reduced evidential value, and this issue can be addressed by using the sunset (power-enhanced) plot feature of the metaviz R package, which visualizes the statistical power for all studies included in a meta-analysis.',\n",
       " 'The novel claim in this paper is that the metameta package has been developed to calculate and visualize study-level statistical power for a range of hypothetical effect sizes, providing an indication of the evidential value of the body of evidence.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://doi.org/10.1177/25152459221147260Advances in Methods and  \\nPractices in Psychological Science\\nJanuary-March 2023, Vol. 6, No. 1, \\npp. 1 –18\\n© The Author(s) 2023\\nArticle reuse guidelines: \\nsagepub.com/journals-permissions\\nDOI: 10.1177/25152459221147260www.psychologicalscience.org/AMPPSASSOCIATION FOR\\nPSYCHOLOGICAL SCIENCE\\nCreative Commons CC BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License  \\n(https://creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without further permission \\nprovided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).Tutorial\\nStatistical power is the probability that a study design and \\nstatistical test combination can detect hypothetical effect sizes of interest. An a priori power analysis is often used to determine a sample-size (or observation number) parameter using three other parameters: a desired power level, hypothetical effect size, and alpha level. Because any one of these four parameters is a function of the remaining three parameters, statistical power can also be calculated using the parameters of sample size, alpha level, and hypothetical effect size. It follows that when holding alpha level and sample size constant, statistical power decreases as the hypothetical effect size decreases. Therefore, one can compute the range of effect sizes that can be reliably detected (i.e., those associated with high statistical power) with a given sample size and alpha level. For instance, a study design with sample size of 40 and an alpha of .05 (two-tailed) that uses a paired samples t test has an 80% chance to detect an effect size of 0.45 but has only a 50% chance of detecting of an effect size of 0.32 (Fig. 1). In other words, this study design and test combination would have a good chance of missing effect sizes smaller than 0.45.\\nIn addition to having a lower probability of discover -\\ning true effects (Button et\\xa0al., 2013), study design/test combinations that cannot reliably detect a wide range of effects also have a lower probability that statistically sig-nificant results represent true effects (Ioannidis, 2005). 1147260 AMPXXX10.1177/25152459221147260QuintanaAdvances in Methods and Practices in Psychological Science\\nresearch-article 2023\\nCorresponding Author:\\nDaniel S. Quintana, Department of Psychology, University of Oslo, Oslo, Norway Email: daniel.quintana@psykologi.uio.noA Guide for Calculating Study-Level  \\nStatistical Power for Meta-Analyses\\nDaniel S. Quintana1,2,3,4\\n1Department of Psychology, University of Oslo, Oslo, Norway; 2Department of Rare Disorders and \\nDisabilities, Oslo University Hospital, Oslo, Norway; 3Norwegian Centre for Mental Disorders Research, \\nUniversity of Oslo, Oslo, Norway; and 4KG Jebsen Centre for Neurodevelopmental Disorders, University \\nof Oslo, Oslo, Norway\\nAbstract',\n",
       " 'University of Oslo, Oslo, Norway; and 4KG Jebsen Centre for Neurodevelopmental Disorders, University \\nof Oslo, Oslo, Norway\\nAbstract\\nMeta-analysis is a popular approach in the psychological sciences for synthesizing data across studies. However, the credibility of meta-analysis outcomes depends on the evidential value of studies included in the body of evidence used for data synthesis. One important consideration for determining a study’s evidential value is the statistical power of the study’s design/statistical test combination for detecting hypothetical effect sizes of interest. Studies with a design/test combination that cannot reliably detect a wide range of effect sizes are more susceptible to questionable research practices and exaggerated effect sizes. Therefore, determining the statistical power for design/test combinations for studies included in meta-analyses can help researchers make decisions regarding confidence in the body of evidence. Because the one true population effect size is unknown when hypothesis testing, an alternative approach is to determine statistical power for a range of hypothetical effect sizes. This tutorial introduces the metameta R package and web app, \\nwhich facilitates the straightforward calculation and visualization of study-level statistical power in meta-analyses for a range of hypothetical effect sizes. Readers will be shown how to reanalyze data using information typically presented in meta-analysis forest plots or tables and how to integrate the metameta package when reporting novel meta-analyses. A step-by-step companion screencast video tutorial is also provided to assist readers using the R package.\\nKeywords\\nmeta-analysis, statistical power, R package\\nReceived 7/18/22; Revision accepted 11/30/22',\n",
       " '2 Quintana\\nIn addition, such study design/test combinations tend to \\nbe associated with questionable research practices (Dwan et\\xa0al., 2008) and are more likely to report exaggerated effect sizes (Ioannidis, 2008; Rochefort-Maranda, 2021). In light of these factors, the contribution of low statistical power to the reproducibility crisis in the psychological sciences has become increasingly recognized (Button et\\xa0al., 2013; Munafò et\\xa0al., 2017; Walum et\\xa0al., 2016). However, despite meta-analysis being often considered the “gold standard” of evidence (but see Stegenga, 2011), the role of study-level statistical power for calculating effect sizes in meta-analysis outcomes is rarely consid-ered. This can be a critical oversight because studies included in a meta-analysis that are not designed to reli-ably detect meaningful effect sizes have reduced eviden-tial value, which diminishes confidence in the body of evidence. Although inverse variance weighting and related approaches can reduce the influence of studies with larger variance (i.e., those with less statistical power) on the summary effect-size estimate, these procedures only attenuate the influence of studies that have larger variances relative to other studies in the meta-analysis. Moreover, this attenuation can be quite modest for random-effects meta-analysis, which is the dominant meta-analysis model in the psychological sciences. Evaluating statistical power for study heterogeneity and moderator tests (Hedges & Pigott, 2004; Huedo-Medina et\\xa0al., 2006) can also be used to help determine the overall evidential value of a meta-analysis (Bryan et\\xa0al., 2021; Linden & Hönekopp, 2021); however, these analyses are beyond the scope of this article and associated R package.One possible reason for the lack of consideration of \\nstudy-level statistical power in meta-analysis is that it can be time-consuming to calculate statistical power for a body of studies if data were to be directly extracted from each study. A recently proposed solution for cal-culating study-level statistical power is the sunset (power-enhanced) plot (Fig. 2), which is a feature of the metaviz R package (Kossmeier et\\xa0al., 2020). Although sunset plots are informative because they visualize the statistical power for all studies included in a meta-analysis, they can visualize statistical power for only one effect size of interest at a time. By default, this effect size is the observed summary effect size calculated for the asso-ciated meta-analysis (although statistical power for any single effect size of interest can be calculated).\\nDespite the utility of sunset plots, there are some']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[section[\"page_content\"] for section in sections]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
