{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "# full_lit_df = generate_literature_csv_from_pdf(\"data/weather.pdf\", \"Author\", \"Title\", \"Publication Year\", output_path=\"full_lit.csv\")\n",
    "df = autosearch_missing_abstracts(\"full_lit.csv\", \"trash.csv\")\n",
    "column arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_focal_claims(pdf_path: str, max_claims = 5) -> list:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=200)\n",
    "    docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "    claims = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i >= max_claims:\n",
    "            is there a cleverer way\n",
    "            break\n",
    "        prompt = f\"Extract the novel claim from the following research paper snippet. Only give the claim that is novel and unique to the publication. Ignore claims from previous references mentioned in the paper. Simply reproduce the novel claim within one sentence (Example responses: 'A low sodium diet reduces the risk of heart disease.', 'The attention mechanism was not pioneered in transformer architectures.'). If there is no claim, return an empty string. Paper snippet: <<<{doc.page_content}>>>\"\n",
    "        system_prompt = \"You are an AI model that extracts the central claim from research papers. You state the claim in a single sentence as if you were the original author.\"\n",
    "        response = perform_chat_completion(prompt= prompt, system_message=system_prompt, temperature=0)\n",
    "        claims.append(response)\n",
    "    return claims\n",
    "claims = extract_focal_claims(\"data/manuscript.pdf\")\n",
    "for claim in claims:\n",
    "    print(claim)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions import *\n",
    "# presented_claim = \"Humor is more important for dating success than physical attractiveness.\" \n",
    "# zotero_file = \"data/humorXdating_literature.csv\"\n",
    "# data_formatted = format_texts_from_csv(zotero_file, \"Abstract Note\", \"Author\", \"Title\", \"Publication Year\")\n",
    "# print(data_formatted[[\"file_content\", \"reference\"]].head(3))\n",
    "# vectorstore_folder_name = generate_vectorstore(data_formatted, zotero_file, max_doc_size = 4000)\n",
    "# relevant_docs = get_relevant_docs(presented_claim, vectorstore_folder_name)\n",
    "# responses, summary_response = generate_adversarial_texts(presented_claim, relevant_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
